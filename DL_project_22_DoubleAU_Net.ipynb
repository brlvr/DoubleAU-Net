{"cells":[{"cell_type":"markdown","metadata":{"id":"Q-guWQoeaCQn"},"source":["ðŸ§‘**Roe Barlev**\n","\n","ðŸ§‘**Ron Dudkman**"]},{"cell_type":"markdown","metadata":{"id":"2XcpivolvbeY"},"source":["# 1 Setup "]},{"cell_type":"markdown","metadata":{"id":"YHhidc5c_VQm"},"source":["Connect to drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ytgzZRR59Qwd","outputId":"a7f6d709-88dd-4ec1-aed6-d15713332083","executionInfo":{"status":"ok","timestamp":1666016455354,"user_tz":-180,"elapsed":7502,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","GPU 0: Tesla T4 (UUID: GPU-377efaf8-b009-9b8a-c01b-711a097a3ac0)\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!nvidia-smi -L"]},{"cell_type":"markdown","metadata":{"id":"xlTOx4YeVz_Y"},"source":["## 1.1 Libreries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CoYqijDEvAWa"},"outputs":[],"source":["!pip install ipyplot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuiENacYVy7O"},"outputs":[],"source":["import os, cv2\n","import numpy as np\n","import pandas as pd\n","import random, tqdm\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import albumentations as album\n","\n","import ipyplot\n","import os.path\n","import zipfile\n","from glob import glob\n","from google.colab.patches import cv2_imshow\n","\n","from sklearn.model_selection import train_test_split\n","\n","\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import torchvision\n","from torchvision.models import vgg19\n","from torchvision.ops import *\n","from torch.nn import functional as F\n","from torch.optim import NAdam, Adam\n","from torch.optim import lr_scheduler\n","\n","from datetime import datetime\n","\n","import pickle\n","\n","import random\n","from tqdm import tqdm\n","import tifffile as tif\n","from albumentations import (\n","    PadIfNeeded,\n","    HorizontalFlip,\n","    VerticalFlip,\n","    CenterCrop,\n","    Crop,\n","    Compose,\n","    Transpose,\n","    RandomRotate90,\n","    ElasticTransform,\n","    GridDistortion,\n","    OpticalDistortion,\n","    RandomSizedCrop,\n","    OneOf,\n","    CLAHE,\n","    RandomBrightnessContrast,\n","    RandomGamma,\n","    HueSaturationValue,\n","    RGBShift,\n","    RandomBrightness,\n","    RandomContrast,\n","    MotionBlur,\n","    MedianBlur,\n","    GaussianBlur,\n","    GaussNoise,\n","    ChannelShuffle,\n","    CoarseDropout\n",")\n","\n","from requests import get\n","from torchsummary import summary"]},{"cell_type":"markdown","metadata":{"id":"aTA7pQjaQ4ey"},"source":["## 1.2 Config"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"TQ_U0U2-NbWi","executionInfo":{"status":"ok","timestamp":1666016465219,"user_tz":-180,"elapsed":6,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["config = {}\n","\n","# Link for the bowl dataset: https://www.kaggle.com/competitions/data-science-bowl-2018/data\n","# Link for the CVC dataset : https://www.kaggle.com/datasets/balraj98/cvcclinicdb\n","\n","##################### Configuration: ######################\n","''' choose True if u need to arrange your data for the first time'''\n","#config['first_time_data_arrangement'] = True\n","config['first_time_data_arrangement'] = False\n","\n","''' choose if you want to use the interpolation technique '''\n","#config ['use_interpolation'] = True\n","config['use_interpolation']= False\n","\n","''' choose the dataset u want to work with'''\n","#config['dataset'] = 'bowl'\n","config['dataset']= 'CVC'\n","\n","''' change directories paths'''\n","config['data_path'] = '/content/Datasets//' \n","config['output_path'] = '/content/output/'\n","\n","#############################################################\n","config['CVC_ClinicDB_zip_path'] = config['data_path']+'CVC-ClinicDB.zip'\n","config['bowl_2018_zip_path'] = config['data_path']+'data-science-bowl-2018.zip'\n","config['bowl_2018_train_zip_path'] = '/content/data-science-bowl-2018/stage1_train.zip'\n","\n","config['CVC_ClinicDB_new_zip_path'] = config['data_path']+'CVC-ClinicDB-new_data.zip'\n","config['bowl_2018_new_zip_path'] = config['data_path']+'bowl_dataset-new_data.zip'\n","\n","if config['dataset']=='bowl':\n","  config['input_w']=256\n","  config['input_h']=256\n","  config['lr'] = lr = 1e-4\n","  config['batch_size']=16\n","else:\n","  config['input_w']=384\n","  config['input_h']=288\n","  #config['lr'] = lr = 0.001 \n","  config['lr'] = 1e-4\n","  if config['use_interpolation'] == True:\n","    config['batch_size']=16\n","  elif config['use_interpolation'] == False: \n","    config ['batch_size']=4 \n","\n","config['notebook_name'] =  get('http://172.28.0.2:9000/api/sessions').json()[0]['name']\n","\n","config['name']=None\n","config['epochs']=30\n","\n","config['eps'] = 1e-07\n","config['num_workers']=2\n","config['squeeze_ratio']=8\n","config['smooth'] = 1e-15\n","\n","config['early_stopping_patience'] = 15\n","config['scheduler_reduce_lr_factor'] = 0.1\n","config['scheduler_patience'] = 10\n","#############################################################"]},{"cell_type":"markdown","metadata":{"id":"NV-Gga5j8l7S"},"source":["## 1.3 Utils"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"eeDjDhNCY-cL","executionInfo":{"status":"ok","timestamp":1666016467640,"user_tz":-180,"elapsed":7,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["def create_dir(path):\n","    \"\"\" Create a directory. \"\"\"\n","    try:\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","    except OSError:\n","        print(f\"Error: creating directory with name {path}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"RcQTzlteZAYc","executionInfo":{"status":"ok","timestamp":1666016467640,"user_tz":-180,"elapsed":6,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["def unzip_by_path(src_zip_path, dest_unzip_path=\"/content/\"):\n","  \n","  src_zip_name = src_zip_path.split('.')[0].split('/')[-1] #takes the first name before the .zip ending\n","  dest_unzip_path = dest_unzip_path + src_zip_name \n","\n","  with zipfile.ZipFile(src_zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(dest_unzip_path)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"z5QuPt_b2b6k","executionInfo":{"status":"ok","timestamp":1666016467640,"user_tz":-180,"elapsed":6,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["def print_both(*args,output_file_path):\n","    output_file = open(output_file_path, \"a\") #open file to save all prints to it\n","    toprint = ' '.join([str(arg) for arg in args])\n","    print(toprint)\n","    output_file.write(toprint)\n","    output_file.close()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"_ypYQ5hZ8Khr","executionInfo":{"status":"ok","timestamp":1666016467641,"user_tz":-180,"elapsed":6,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["def dict_to_txt(dict_,output_file_path):\n","  ''' save dict to txt file'''\n","\n","  output_file = open(output_file_path, \"w\") #open file to save all prints to it\n","  for dict_ele in str(dict_).split(','):\n","    output_file.write(str(dict_ele)+'\\n')\n","  output_file.close()\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"xsRrUe1tha8e","executionInfo":{"status":"ok","timestamp":1666016467641,"user_tz":-180,"elapsed":6,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["def save_list(list_,output_path):\n","  with open(output_path, \"wb\") as fp:   #Pickling\n","    pickle.dump(list_, fp)\n","    fp.close()\n","\n","\n","def load_list(output_path):\n","  with open(output_path, \"rb\") as fp:   # Unpickling\n","    list_ = pickle.load(fp)\n","    fp.close()\n","  \n","  return list_"]},{"cell_type":"markdown","metadata":{"id":"waFti2N4vhyh"},"source":["# 2 Datasets extraction to local env"]},{"cell_type":"markdown","metadata":{"id":"_oiu44ubfQ6C"},"source":["Extract Datasets to local workspace"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"h-8Opwax_yo0","executionInfo":{"status":"ok","timestamp":1666016480612,"user_tz":-180,"elapsed":12977,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["src_zip_paths = [config['CVC_ClinicDB_zip_path'],\n","                 config['bowl_2018_zip_path'],\n","                 config['bowl_2018_train_zip_path'],\n","                 config['CVC_ClinicDB_new_zip_path'],\n","                 config['bowl_2018_new_zip_path']]\n","\n","if config['first_time_data_arrangement']: # if it is the first time foro creating the zip new data\n","  if config['dataset']=='bowl':\n","    unzip_by_path(src_zip_paths[1], dest_unzip_path=\"/content/\")\n","    unzip_by_path(src_zip_paths[2], dest_unzip_path=\"/content/bowl_dataset/\") \n","  else:\n","    unzip_by_path(src_zip_paths[0], dest_unzip_path=\"/content/\")\n","\n","elif not config['first_time_data_arrangement']: #when you have the new data just unzip it to this location\n","  if config['dataset']=='bowl':\n","    unzip_by_path(src_zip_paths[4], dest_unzip_path=\"/content/\") \n","  else:\n","    unzip_by_path(src_zip_paths[3], dest_unzip_path=\"/content/\")"]},{"cell_type":"markdown","metadata":{"id":"1O-K4e_vtNbR"},"source":["#3 CVC-ClinicDB"]},{"cell_type":"markdown","metadata":{"id":"Uz7IC0i5Rlpj"},"source":["##3.1 Utils for this dataset"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"wUKvcE5NufJo","executionInfo":{"status":"ok","timestamp":1666016480613,"user_tz":-180,"elapsed":22,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["\n","def load_data(images_folder_path, masks_folder_path):\n","  '''load the data to 2 path lists for images and masks.'''\n","\n","  images = [images_folder_path+name for name in os.listdir(images_folder_path)]\n","  masks = [masks_folder_path+name for name in os.listdir(masks_folder_path)]\n","  return images, masks\n","\n","def read_data_to_list(images_path, masks_path):\n","    \"\"\" Read the image and mask from the given images and masks lists of paths. \"\"\"\n","\n","    images = []\n","    masks =[]\n","    for xi,yi in zip(images_path,masks_path):\n","      images.append(cv2.imread(xi, cv2.IMREAD_COLOR))\n","      masks.append(cv2.imread(yi, cv2.IMREAD_COLOR))\n","    return images, masks\n","\n","def split_data(images,masks):\n","  ''' split the data to 80-10-10'''\n","  train_size=int(0.8*len(images))\n","  valid_size=int(0.1*len(images))\n","  test_size=int(0.1*len(images))\n","  \n","  train_x, test_x = train_test_split(images, test_size=test_size, random_state=0)\n","  train_y, test_y = train_test_split(masks, test_size=test_size, random_state=0)\n","\n","  train_x, valid_x = train_test_split(train_x, test_size=valid_size, random_state=0)\n","  train_y, valid_y = train_test_split(train_y, test_size=valid_size, random_state=0)\n","\n","  return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n","    \n","def read_data(x, y):\n","    \"\"\" Read the image and mask from the given path. \"\"\"\n","    image = cv2.imread(x, cv2.IMREAD_COLOR)\n","    mask = cv2.imread(y, cv2.IMREAD_COLOR)\n","    return image, mask"]},{"cell_type":"markdown","metadata":{"id":"2C33rc3HUJ9m"},"source":["##3.2 Read and learn the data"]},{"cell_type":"markdown","metadata":{"id":"eymbDU7NS8XS"},"source":["Read images and masks paths & read images and masks as images"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"w8MUF2AD0L15","executionInfo":{"status":"ok","timestamp":1666016480614,"user_tz":-180,"elapsed":22,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["if config['first_time_data_arrangement']:\n","  CVC_images_path, CVC_masks_path = load_data(\"/content/CVC-ClinicDB/PNG/Original/\", \"/content/CVC-ClinicDB/PNG/Ground Truth/\")\n","  CVC_images, CVC_masks = read_data_to_list(CVC_images_path, CVC_masks_path)\n","\n","  print(\"Numbers of images for CVC-ClinicDB: \" + str(len(CVC_images)))\n","  print(\"Numbers of masks for CVC-ClinicDB: \" + str(len(CVC_masks_path)))\n"]},{"cell_type":"markdown","metadata":{"id":"qUhCGcbbQhKe"},"source":["Images shape check"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Lq8TtblQQgHc","executionInfo":{"status":"ok","timestamp":1666016480614,"user_tz":-180,"elapsed":21,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["if config['first_time_data_arrangement']:\n","  check_images_shape = {img.shape for img in CVC_images} #create a set of values, if we get 1 element it means all images are the same size\n","  print(\"images shape is (H,W,C):\"+str(check_images_shape))\n","  check_masks_shape = {mask.shape for mask in CVC_masks} #create a set of values, if we get 1 element it means all images are the same size\n","  print(\"masks shape is (H,W,C):\"+str(check_masks_shape))"]},{"cell_type":"markdown","metadata":{"id":"TFcRlX31TIWO"},"source":["## 3.3 Split the data"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"x_Rj-8YAPiNJ","executionInfo":{"status":"ok","timestamp":1666016480615,"user_tz":-180,"elapsed":21,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["if config['first_time_data_arrangement']:\n","  (CVC_train_images_path, CVC_train_masks_path), (CVC_valid_images_path, CVC_valid_masks_path), (CVC_test_images_path, CVC_test_masks_path) = split_data(CVC_images_path,CVC_masks_path)\n","  print(\"Numbers of CVC_train_images: \" + str(len(CVC_train_images_path)))\n","  print(\"Numbers of CVC_valid_images: \" + str(len(CVC_valid_images_path)))\n","  print(\"Numbers of CVC_test_images: \" + str(len(CVC_test_images_path)))\n","  print(\"Numbers of CVC_train_masks: \" + str(len(CVC_train_masks_path)))\n","  print(\"Numbers of CVC_valid_masks: \" + str(len(CVC_valid_masks_path)))\n","  print(\"Numbers of CVC_test_masks: \" + str(len(CVC_test_masks_path)))\n"]},{"cell_type":"markdown","metadata":{"id":"3XDgFUi1UtWT"},"source":["## 3.4 Data examples"]},{"cell_type":"markdown","metadata":{"id":"m_hE5pdCTM4R"},"source":["Show the data by images and masks"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Tu4U-zeqL6Iq","executionInfo":{"status":"ok","timestamp":1666016480615,"user_tz":-180,"elapsed":21,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["if config['first_time_data_arrangement']:\n","  ipyplot.plot_images(CVC_images, max_images=7, img_width=150, force_b64=True)\n","  ipyplot.plot_images(CVC_masks, max_images=7, img_width=150, force_b64=True)"]},{"cell_type":"markdown","metadata":{"id":"RYFIaj86TQY5"},"source":["Show images and masks by paths"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Ja41sLJ0-k8a","executionInfo":{"status":"ok","timestamp":1666016480615,"user_tz":-180,"elapsed":20,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["if config['first_time_data_arrangement']:\n","  ipyplot.plot_images(CVC_train_images_path, max_images=7, img_width=150, force_b64=True)\n","  ipyplot.plot_images(CVC_train_masks_path, max_images=7, img_width=150, force_b64=True)"]},{"cell_type":"markdown","metadata":{"id":"qWhyoMibTVvj"},"source":["## 3.5 Augmentations"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"_hte7r0yL0Du","executionInfo":{"status":"ok","timestamp":1666016480616,"user_tz":-180,"elapsed":21,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["def augment_data(images, masks, W, H, save_path, augment=True):\n","    \"\"\" Performing data augmentation. \"\"\"\n","    #W = 384\n","    #H = 288\n","    crop_size = (H-32, W-32)\n","    size = (W, H)\n","\n","    for image, mask in tqdm(zip(images, masks), total=len(images)):\n","        image_name = image.split(\"/\")[-1].split(\".\")[0]\n","        mask_name = mask.split(\"/\")[-1].split(\".\")[0]\n","\n","        x, y = read_data(image, mask)\n","        try:\n","            h, w, c = x.shape\n","        except Exception as e:\n","            image = image[:-1]\n","            x, y = read_data(image, mask)\n","            h, w, c = x.shape\n","\n","        if augment == True:\n","            ## Center Crop\n","            aug = CenterCrop(p=1, height=crop_size[0], width=crop_size[1])\n","            augmented = aug(image=x, mask=y)\n","            x1 = augmented['image']\n","            y1 = augmented['mask']\n","\n","            ## Crop\n","            x_min = 0\n","            y_min = 0\n","            x_max = x_min + size[0]\n","            y_max = y_min + size[1]\n","\n","            aug = Crop(p=1, x_min=x_min, x_max=x_max, y_min=y_min, y_max=y_max)\n","            augmented = aug(image=x, mask=y)\n","            x2 = augmented['image']\n","            y2 = augmented['mask']\n","\n","            ## Random Rotate 90 degree\n","            aug = RandomRotate90(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x3 = augmented['image']\n","            y3 = augmented['mask']\n","\n","            ## Transpose\n","            aug = Transpose(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x4 = augmented['image']\n","            y4 = augmented['mask']\n","\n","            ## ElasticTransform\n","            aug = ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)\n","            augmented = aug(image=x, mask=y)\n","            x5 = augmented['image']\n","            y5 = augmented['mask']\n","\n","            ## Grid Distortion\n","            aug = GridDistortion(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x6 = augmented['image']\n","            y6 = augmented['mask']\n","\n","            ## Optical Distortion\n","            aug = OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)\n","            augmented = aug(image=x, mask=y)\n","            x7 = augmented['image']\n","            y7 = augmented['mask']\n","\n","            ## Vertical Flip\n","            aug = VerticalFlip(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x8 = augmented['image']\n","            y8 = augmented['mask']\n","\n","            ## Horizontal Flip\n","            aug = HorizontalFlip(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x9 = augmented['image']\n","            y9 = augmented['mask']\n","\n","            ## Grayscale\n","            x10 = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n","            y10 = y\n","\n","            ## Grayscale Vertical Flip\n","            aug = VerticalFlip(p=1)\n","            augmented = aug(image=x10, mask=y10)\n","            x11 = augmented['image']\n","            y11 = augmented['mask']\n","\n","            ## Grayscale Horizontal Flip\n","            aug = HorizontalFlip(p=1)\n","            augmented = aug(image=x10, mask=y10)\n","            x12 = augmented['image']\n","            y12 = augmented['mask']\n","\n","            ## Grayscale Center Crop\n","            aug = CenterCrop(p=1, height=crop_size[0], width=crop_size[1])\n","            augmented = aug(image=x10, mask=y10)\n","            x13 = augmented['image']\n","            y13 = augmented['mask']\n","\n","            ##\n","            aug = RandomBrightnessContrast(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x14 = augmented['image']\n","            y14 = augmented['mask']\n","\n","            aug = RandomGamma(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x15 = augmented['image']\n","            y15 = augmented['mask']\n","\n","            aug = HueSaturationValue(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x16 = augmented['image']\n","            y16 = augmented['mask']\n","\n","            aug = RGBShift(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x17 = augmented['image']\n","            y17 = augmented['mask']\n","\n","            aug = RandomBrightness(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x18 = augmented['image']\n","            y18 = augmented['mask']\n","\n","            aug = RandomContrast(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x19 = augmented['image']\n","            y19 = augmented['mask']\n","\n","            aug = MotionBlur(p=1, blur_limit=7)\n","            augmented = aug(image=x, mask=y)\n","            x20 = augmented['image']\n","            y20 = augmented['mask']\n","\n","            aug = MedianBlur(p=1, blur_limit=9)\n","            augmented = aug(image=x, mask=y)\n","            x21 = augmented['image']\n","            y21 = augmented['mask']\n","\n","            aug = GaussianBlur(p=1, blur_limit=9)\n","            augmented = aug(image=x, mask=y)\n","            x22 = augmented['image']\n","            y22 = augmented['mask']\n","\n","            aug = GaussNoise(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x23 = augmented['image']\n","            y23 = augmented['mask']\n","\n","            aug = ChannelShuffle(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x24 = augmented['image']\n","            y24 = augmented['mask']\n","\n","            aug = CoarseDropout(p=1, max_holes=8, max_height=32, max_width=32)\n","            augmented = aug(image=x, mask=y)\n","            x25 = augmented['image']\n","            y25 = augmented['mask']\n","\n","            images = [\n","                x, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10,\n","                x11, x12, x13, x14, x15, x16, x17, x18, x19, x20,\n","                x21, x22, x23, x24, x25\n","            ]\n","            masks  = [\n","                y, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10,\n","                y11, y12, y13, y14, y15, y16, y17, y18, y19, y20,\n","                y21, y22, y23, y24, y25\n","            ]\n","\n","        else:\n","            images = [x]\n","            masks  = [y]\n","\n","        idx = 0\n","        for i, m in zip(images, masks):\n","            i = cv2.resize(i, size)\n","            m = cv2.resize(m, size)\n","\n","            tmp_image_name = f\"{image_name}_{idx}.jpg\"\n","            tmp_mask_name  = f\"{mask_name}_{idx}.jpg\"\n","\n","            image_path = os.path.join(save_path, \"image/\", tmp_image_name)\n","            mask_path  = os.path.join(save_path, \"mask/\", tmp_mask_name)\n","\n","            cv2.imwrite(image_path, i)\n","            cv2.imwrite(mask_path, m)\n","\n","            idx += 1\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wxVp3uCZU7Qk"},"source":["## 3.6 Save aug. data "]},{"cell_type":"markdown","metadata":{"id":"Omn0RU5dj_mn"},"source":["Create directories to save augmentations later on"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"9S3BgFeEj1VG","executionInfo":{"status":"ok","timestamp":1666016480616,"user_tz":-180,"elapsed":21,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["if config['first_time_data_arrangement']:\n","  create_dir(\"/content/CVC-ClinicDB/new_data/train/image/\")\n","  create_dir(\"/content/CVC-ClinicDB/new_data/train/mask/\")\n","  create_dir(\"/content/CVC-ClinicDB/new_data/valid/image/\")\n","  create_dir(\"/content/CVC-ClinicDB/new_data/valid/mask/\")\n","  create_dir(\"/content/CVC-ClinicDB/new_data/test/image/\")\n","  create_dir(\"/content/CVC-ClinicDB/new_data/test/mask/\")\n"]},{"cell_type":"markdown","metadata":{"id":"OCgkEQyDj9fG"},"source":["Use augmentations"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"wKfGZAeaMVnL","executionInfo":{"status":"ok","timestamp":1666016480617,"user_tz":-180,"elapsed":21,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["if config['first_time_data_arrangement']:\n","  W, H = [config['input_w'], config['input_h']] #size to resize if needed after augmentations\n","  augment_data(CVC_train_images_path, CVC_train_masks_path, W, H, \"/content/CVC-ClinicDB/new_data/train/\", augment=True)\n","  augment_data(CVC_valid_images_path, CVC_valid_masks_path, W, H, \"/content/CVC-ClinicDB/new_data/valid/\", augment=False)\n","  augment_data(CVC_test_images_path, CVC_test_masks_path, W, H, \"/content/CVC-ClinicDB/new_data/test/\", augment=False)\n"]},{"cell_type":"markdown","source":["### 3.6.1 Save aug data as ZIP file"],"metadata":{"id":"WiNax0cZQatu"}},{"cell_type":"code","source":["if config['first_time_data_arrangement']: a=1 # if it is \"a\" first time a will be 1\n","elif not config['first_time_data_arrangement']: a=0 #not a first time \"a\" will be 0\n","#using shell commend to zip only if it is a first time.\n","!if [ $a -eq 1 ]; then zip -r /content/gdrive/MyDrive/CVC-ClinicDB-new_data.zip /content/CVC-ClinicDB/new_data; fi\n"],"metadata":{"id":"-ZeD5BbYQfy1","executionInfo":{"status":"ok","timestamp":1666016480617,"user_tz":-180,"elapsed":21,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xvA3iPtdVHOI"},"source":["## 3.7 Dataset class"]},{"cell_type":"markdown","metadata":{"id":"b10zXdPO0sZS"},"source":["define Dataset class "]},{"cell_type":"code","execution_count":21,"metadata":{"id":"FeUJW8Nnw2Qe","executionInfo":{"status":"ok","timestamp":1666016480618,"user_tz":-180,"elapsed":21,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["class CvcClinicDbDataset(Dataset):\n","    def __init__(self, CVC_images_folder, CVC_masks_folder, transform = None):\n","        '''define self parameters, root folders to read from images and masks '''\n","        self.CVC_images_folder = CVC_images_folder\n","        self.CVC_masks_folder = CVC_masks_folder\n","        self.transform = transform\n","        # get to self parameters images and masks path lists for when we want to get item from dataset\n","        self.CVC_images_path, self.CVC_masks_path = load_data(self.CVC_images_folder, self.CVC_masks_folder)\n","\n","    def __getitem__(self, index):\n","        CVC_image_path = self.CVC_images_path[index]\n","        CVC_mask_path = self.CVC_masks_path[index]\n","        \n","        CVC_image = cv2.imread(CVC_image_path, cv2.IMREAD_COLOR).astype(np.float32)/255.0 #need to read them as float for NN\n","        CVC_mask = cv2.imread(CVC_mask_path, cv2.IMREAD_GRAYSCALE).astype(np.float32)/255.0 #need to read them as float for NN\n","\n","        sample = {'image': CVC_image, 'mask': CVC_mask}\n","        if self.transform:\n","            #print(\"in transform!\")\n","            sample = self.transform(sample)\n","        return sample\n","\n","\n","    def __len__(self):\n","        return len(self.CVC_images_path)\n","\n","    def load_data(images_folder_path, masks_folder_path):\n","        '''load the data to 2 path lists for images and masks.'''\n","\n","        images = [images_folder_path+name for name in os.listdir(images_folder_path)]\n","        masks = [masks_folder_path+name for name in os.listdir(masks_folder_path)]\n","        return images, masks\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"kdcYblPTKybi","executionInfo":{"status":"ok","timestamp":1666016480618,"user_tz":-180,"elapsed":21,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["class ToTensor(object):\n","    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n","\n","    def __call__(self, sample):\n","        image, mask = sample['image'], sample['mask']\n","\n","        # swap color axis because\n","        # numpy image: H x W x C\n","        # torch image: C X H X W\n","        image = image.transpose((2, 0, 1))\n","        mask = np.expand_dims(mask, axis=-1)\n","        mask = mask.transpose((2, 0, 1))\n","        #print(image)\n","        return {'image': torch.from_numpy(image),\n","                'mask': torch.from_numpy(mask)}"]},{"cell_type":"markdown","metadata":{"id":"0OBfpdhrVPXd"},"source":["## 3.8 DataLoaders for train and validation"]},{"cell_type":"markdown","metadata":{"id":"ojzE9TxR-eXt"},"source":["Load dataset class"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"szrL6KZ37TE2","executionInfo":{"status":"ok","timestamp":1666016480618,"user_tz":-180,"elapsed":20,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["CVC_clinic_DB_train = CvcClinicDbDataset(\"/content/CVC-ClinicDB-new_data/content/CVC-ClinicDB/new_data/train/image/\", \"/content/CVC-ClinicDB-new_data/content/CVC-ClinicDB/new_data/train/mask/\",transform = ToTensor())"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"jSGoMEMzKQwz","executionInfo":{"status":"ok","timestamp":1666016480619,"user_tz":-180,"elapsed":21,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["train_dataloader = DataLoader(CVC_clinic_DB_train, batch_size=config['batch_size'],\n","                        shuffle=True, num_workers= config['num_workers'])"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"tq1g0TC_McVs","executionInfo":{"status":"ok","timestamp":1666016480619,"user_tz":-180,"elapsed":21,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["CVC_clinic_DB_valid = CvcClinicDbDataset(\"/content/CVC-ClinicDB-new_data/content/CVC-ClinicDB/new_data/valid/image/\", \"/content/CVC-ClinicDB-new_data/content/CVC-ClinicDB/new_data/valid/mask/\",transform = ToTensor())"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"Nyfz086lMd5i","executionInfo":{"status":"ok","timestamp":1666016480620,"user_tz":-180,"elapsed":21,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["valid_dataloader = DataLoader(CVC_clinic_DB_valid, batch_size=config['batch_size'],\n","                        shuffle=True, num_workers=config['num_workers'])"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"mlKDCEbm3Cvn","executionInfo":{"status":"ok","timestamp":1666016480620,"user_tz":-180,"elapsed":19,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["CVC_clinic_DB_test = CvcClinicDbDataset(\"/content/CVC-ClinicDB-new_data/content/CVC-ClinicDB/new_data/test/image/\", \"/content/CVC-ClinicDB-new_data/content/CVC-ClinicDB/new_data/test/mask/\",transform = ToTensor())\n"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"y_2E9f6l3IVK","executionInfo":{"status":"ok","timestamp":1666016480620,"user_tz":-180,"elapsed":19,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["test_dataloader = DataLoader(CVC_clinic_DB_test, batch_size=config['batch_size'],\n","                        shuffle=True, num_workers=config['num_workers'])"]},{"cell_type":"markdown","metadata":{"id":"wRyK7Mrh8R2c"},"source":["# 4 Data science bowl 2018"]},{"cell_type":"markdown","source":["## 4.1 Utils for this dataset"],"metadata":{"id":"VhFCKtYrMyjk"}},{"cell_type":"code","source":["def load_data(images_folder_path, masks_folder_path):\n","  '''load the data to 2 path lists for images and masks.'''\n","\n","  images = [images_folder_path+name for name in os.listdir(images_folder_path)]\n","  masks = [masks_folder_path+name for name in os.listdir(masks_folder_path)]\n","  return images, masks\n","\n","def read_data_to_list(path_of_the_directory,path_to_save):\n","  \"\"\" Read the image and mask from the given images and masks lists of paths. \"\"\"\n","  create_dir(path_to_save+ \"image/\")\n","  create_dir(path_to_save+ \"mask/\")\n","  images = []\n","  masks = []\n","\n","  for filename in tqdm(os.listdir(path_of_the_directory)):\n","    f = os.path.join(path_of_the_directory,filename)\n","    bowl_image_path, bowl_masks_path = load_data(f + \"/images/\", f + \"/masks/\")\n","\n","    # Getting the image:\n","    images.append(cv2.imread(bowl_image_path[0], cv2.IMREAD_COLOR))\n","\n","    # Getting the mask:\n","    for i,mask in enumerate(bowl_masks_path):\n","      tmp_mask = cv2.imread(mask, cv2.IMREAD_COLOR)\n","      if i==0:\n","        final_mask = tmp_mask\n","      else:\n","        final_mask = cv2.bitwise_or(final_mask, tmp_mask)\n","    masks.append(final_mask)   \n","\n","    # Save images & masks:\n","    image_path = os.path.join(path_to_save, \"image/\", filename +'.jpg')\n","    mask_path  = os.path.join(path_to_save, \"mask/\", filename + '.jpg')\n","\n","    cv2.imwrite(image_path, images[-1])\n","    cv2.imwrite(mask_path, masks[-1])\n","\n","  return images, masks\n","\n","def split_data(images,masks):\n","  ''' split the data to 80-10-10'''\n","  train_size=int(0.8*len(images))\n","  valid_size=int(0.1*len(images))\n","  test_size=int(0.1*len(images))\n","  \n","  train_x, test_x = train_test_split(images, test_size=test_size, random_state=42)\n","  train_y, test_y = train_test_split(masks, test_size=test_size, random_state=42)\n","\n","  train_x, valid_x = train_test_split(train_x, test_size=valid_size, random_state=42)\n","  train_y, valid_y = train_test_split(train_y, test_size=valid_size, random_state=42)\n","\n","  return (train_x, train_y), (valid_x, valid_y), (test_x, test_y) \n","\n","def read_data(x, y):\n","    \"\"\" Read the image and mask from the given path. \"\"\"\n","    image = cv2.imread(x, cv2.IMREAD_COLOR)\n","    mask = cv2.imread(y, cv2.IMREAD_COLOR)\n","    return image, mask   "],"metadata":{"id":"O3o154PRMx7a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 Load the data:"],"metadata":{"id":"GOUcgotRSixf"}},{"cell_type":"code","source":["if config['first_time_data_arrangement']:\n","  path_of_the_directory = '/content/bowl_dataset/stage1_train'\n","  path_to_save = '/content/bowl_dataset/'\n","\n","  bowl_images, bowl_masks = read_data_to_list(path_of_the_directory,path_to_save)\n","\n","  print(\"\\n\\nNumbers of images for bowl dataset: \" + str(len(bowl_images)))\n","  print(\"Numbers of masks for bowl dataset: \" + str(len(bowl_masks)))\n"],"metadata":{"id":"W12RW8nPLB8R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.3 Split the data:"],"metadata":{"id":"MHe-gQmjSx4m"}},{"cell_type":"code","source":["if config['first_time_data_arrangement']:\n","  # Get images & masks paths:\n","  bowl_images_path, bowl_masks_path = load_data(\"/content/bowl_dataset/image/\", \"/content/bowl_dataset/mask/\")\n","\n","  (bowl_train_images_path, bowl_train_masks_path), (bowl_valid_images_path, bowl_valid_masks_path), (bowl_test_images_path, bowl_test_masks_path) = split_data(bowl_images_path,bowl_masks_path)\n","  print(\"Numbers of bowl_train_images: \" + str(len(bowl_train_images_path)))\n","  print(\"Numbers of bowl_valid_images: \" + str(len(bowl_valid_images_path)))\n","  print(\"Numbers of bowl_test_images: \" + str(len(bowl_test_images_path)))\n","  print(\"Numbers of bowl_train_masks: \" + str(len(bowl_train_masks_path)))\n","  print(\"Numbers of bowl_valid_masks: \" + str(len(bowl_valid_masks_path)))\n","  print(\"Numbers of bowl_test_masks: \" + str(len(bowl_test_masks_path)))"],"metadata":{"id":"ZjJZSlnqS3YF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.4 Data examples:"],"metadata":{"id":"o8B4WkAgSmk0"}},{"cell_type":"code","source":["if config['first_time_data_arrangement']:\n","  ipyplot.plot_images(bowl_images, max_images=7, img_width=150, force_b64=True)\n","  ipyplot.plot_images(bowl_masks, max_images=7, img_width=150, force_b64=True)"],"metadata":{"id":"KeFiCe90R1Zt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.5 Augmentations:"],"metadata":{"id":"K9aVBFzRqq2I"}},{"cell_type":"code","source":["def augment_data(images, masks, W, H, save_path, augment=True):\n","    \"\"\" Performing data augmentation. \"\"\"\n","    #W = 384\n","    #H = 288\n","    crop_size = (H-32, W-32)\n","    size = (W, H)\n","\n","    for image, mask in tqdm(zip(images, masks), total=len(images)):\n","        image_name = image.split(\"/\")[-1].split(\".\")[0]\n","        mask_name = mask.split(\"/\")[-1].split(\".\")[0]\n","\n","        x, y = read_data(image, mask)\n","        try:\n","            h, w, c = x.shape\n","        except Exception as e:\n","            image = image[:-1]\n","            x, y = read_data(image, mask)\n","            h, w, c = x.shape\n","\n","        if augment == True:\n","            ## Center Crop\n","            aug = CenterCrop(p=1, height=crop_size[0], width=crop_size[1])\n","            augmented = aug(image=x, mask=y)\n","            x1 = augmented['image']\n","            y1 = augmented['mask']\n","\n","            ## Crop\n","            x_min = 0\n","            y_min = 0\n","            x_max = x_min + size[0]\n","            y_max = y_min + size[1]\n","\n","            aug = Crop(p=1, x_min=x_min, x_max=x_max, y_min=y_min, y_max=y_max)\n","            augmented = aug(image=x, mask=y)\n","            x2 = augmented['image']\n","            y2 = augmented['mask']\n","\n","            ## Random Rotate 90 degree\n","            aug = RandomRotate90(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x3 = augmented['image']\n","            y3 = augmented['mask']\n","\n","            ## Transpose\n","            aug = Transpose(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x4 = augmented['image']\n","            y4 = augmented['mask']\n","\n","            ## ElasticTransform\n","            aug = ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)\n","            augmented = aug(image=x, mask=y)\n","            x5 = augmented['image']\n","            y5 = augmented['mask']\n","\n","            ## Grid Distortion\n","            aug = GridDistortion(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x6 = augmented['image']\n","            y6 = augmented['mask']\n","\n","            ## Optical Distortion\n","            aug = OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)\n","            augmented = aug(image=x, mask=y)\n","            x7 = augmented['image']\n","            y7 = augmented['mask']\n","\n","            ## Vertical Flip\n","            aug = VerticalFlip(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x8 = augmented['image']\n","            y8 = augmented['mask']\n","\n","            ## Horizontal Flip\n","            aug = HorizontalFlip(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x9 = augmented['image']\n","            y9 = augmented['mask']\n","\n","            ## Grayscale\n","            x10 = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n","            y10 = y\n","\n","            ## Grayscale Vertical Flip\n","            aug = VerticalFlip(p=1)\n","            augmented = aug(image=x10, mask=y10)\n","            x11 = augmented['image']\n","            y11 = augmented['mask']\n","\n","            ## Grayscale Horizontal Flip\n","            aug = HorizontalFlip(p=1)\n","            augmented = aug(image=x10, mask=y10)\n","            x12 = augmented['image']\n","            y12 = augmented['mask']\n","\n","            ## Grayscale Center Crop\n","            aug = CenterCrop(p=1, height=crop_size[0], width=crop_size[1])\n","            augmented = aug(image=x10, mask=y10)\n","            x13 = augmented['image']\n","            y13 = augmented['mask']\n","\n","            ##\n","            aug = RandomBrightnessContrast(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x14 = augmented['image']\n","            y14 = augmented['mask']\n","\n","            aug = RandomGamma(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x15 = augmented['image']\n","            y15 = augmented['mask']\n","\n","            aug = HueSaturationValue(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x16 = augmented['image']\n","            y16 = augmented['mask']\n","\n","            aug = RGBShift(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x17 = augmented['image']\n","            y17 = augmented['mask']\n","\n","            aug = RandomBrightness(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x18 = augmented['image']\n","            y18 = augmented['mask']\n","\n","            aug = RandomContrast(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x19 = augmented['image']\n","            y19 = augmented['mask']\n","\n","            aug = MotionBlur(p=1, blur_limit=7)\n","            augmented = aug(image=x, mask=y)\n","            x20 = augmented['image']\n","            y20 = augmented['mask']\n","\n","            aug = MedianBlur(p=1, blur_limit=9)\n","            augmented = aug(image=x, mask=y)\n","            x21 = augmented['image']\n","            y21 = augmented['mask']\n","\n","            aug = GaussianBlur(p=1, blur_limit=9)\n","            augmented = aug(image=x, mask=y)\n","            x22 = augmented['image']\n","            y22 = augmented['mask']\n","\n","            aug = GaussNoise(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x23 = augmented['image']\n","            y23 = augmented['mask']\n","\n","            aug = ChannelShuffle(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x24 = augmented['image']\n","            y24 = augmented['mask']\n","\n","            aug = CoarseDropout(p=1, max_holes=8, max_height=32, max_width=32)\n","            augmented = aug(image=x, mask=y)\n","            x25 = augmented['image']\n","            y25 = augmented['mask']\n","\n","            images = [\n","                x, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10,\n","                x11, x12, x13, x14, x15, x16, x17, x18, x19, x20,\n","                x21, x22, x23, x24, x25\n","            ]\n","            masks  = [\n","                y, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10,\n","                y11, y12, y13, y14, y15, y16, y17, y18, y19, y20,\n","                y21, y22, y23, y24, y25\n","            ]\n","\n","        else:\n","            images = [x]\n","            masks  = [y]\n","\n","        idx = 0\n","        for i, m in zip(images, masks):\n","            i = cv2.resize(i, size)\n","            m = cv2.resize(m, size)\n","\n","            tmp_image_name = f\"{image_name}_{idx}.jpg\"\n","            tmp_mask_name  = f\"{mask_name}_{idx}.jpg\"\n","\n","            image_path = os.path.join(save_path, \"image/\", tmp_image_name)\n","            mask_path  = os.path.join(save_path, \"mask/\", tmp_mask_name)\n","\n","            cv2.imwrite(image_path, i)\n","            cv2.imwrite(mask_path, m)\n","\n","            idx += 1\n","\n"],"metadata":{"id":"y-D-BgXjqw7A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.6 Save aug. data"],"metadata":{"id":"RbBVVeJ4q-Zx"}},{"cell_type":"code","source":["if config['first_time_data_arrangement']:\n","\n","  create_dir(\"/content/bowl_dataset/new_data/train/image/\")\n","  create_dir(\"/content/bowl_dataset/new_data/train/mask/\")\n","  create_dir(\"/content/bowl_dataset/new_data/valid/image/\")\n","  create_dir(\"/content/bowl_dataset/new_data/valid/mask/\")\n","  create_dir(\"/content/bowl_dataset/new_data/test/image/\")\n","  create_dir(\"/content/bowl_dataset/new_data/test/mask/\")"],"metadata":{"id":"A8v4LYirrEMf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if config['first_time_data_arrangement']:\n","  W, H = [config['input_w'], config['input_h']] #size to resize if needed after augmentations\n","  augment_data(bowl_train_images_path, bowl_train_masks_path, W, H, \"/content/bowl_dataset/new_data/train/\", augment=True)\n","  augment_data(bowl_valid_images_path, bowl_valid_masks_path, W, H, \"/content/bowl_dataset/new_data/valid/\", augment=False)\n","  augment_data(bowl_test_images_path, bowl_test_masks_path, W, H, \"/content/bowl_dataset/new_data/test/\", augment=False)\n"],"metadata":{"id":"7alLJfSrsbD7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.6.1 Save aug data as ZIP file"],"metadata":{"id":"K9M3IqFKb-pi"}},{"cell_type":"code","source":["#!zip -r  /content/gdrive/MyDrive/bowl_dataset-new_data.zip /content/bowl_dataset/new_data"],"metadata":{"id":"U8qq6L7ab-pj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if config['first_time_data_arrangement']: a=1 # if it is \"a\" first time a will be 1\n","elif not config['first_time_data_arrangement']: a=0 #not a first time \"a\" will be 0\n","#using shell commend to zip only if it is a first time.\n","!if [ $a -eq 1 ]; then zip -r  /content/bowl_dataset-new_data.zip /content/bowl_dataset-new_data; fi"],"metadata":{"id":"iBIM4pPTw_EZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.7 Dataset class:"],"metadata":{"id":"YMllaZtjrV3w"}},{"cell_type":"code","source":["class BowlDataset(Dataset):\n","    def __init__(self, bowl_images_folder, bowl_masks_folder, transform = None):\n","        '''define self parameters, root folders to read from images and masks '''\n","        self.bowl_images_folder = bowl_images_folder\n","        self.bowl_masks_folder = bowl_masks_folder\n","        self.transform = transform\n","        # get to self parameters images and masks path lists for when we want to get item from dataset\n","        self.bowl_images_path, self.bowl_masks_path = load_data(self.bowl_images_folder, self.bowl_masks_folder)\n","\n","    def __getitem__(self, index):\n","        bowl_image_path = self.bowl_images_path[index]\n","        bowl_mask_path = self.bowl_masks_path[index]\n","        \n","        bowl_image = cv2.imread(bowl_image_path, cv2.IMREAD_COLOR).astype(np.float32)/255.0 #need to read them as float for NN\n","        bowl_mask = cv2.imread(bowl_mask_path, cv2.IMREAD_GRAYSCALE).astype(np.float32)/255.0 #need to read them as float for NN\n","\n","        sample = {'image': bowl_image, 'mask': bowl_mask}\n","        if self.transform:\n","            #print(\"in transform!\")\n","            sample = self.transform(sample)\n","        return sample\n","\n","\n","    def __len__(self):\n","        return len(self.bowl_images_path)\n","\n","    def load_data(images_folder_path, masks_folder_path):\n","        '''load the data to 2 path lists for images and masks.'''\n","\n","        images = [images_folder_path+name for name in os.listdir(images_folder_path)]\n","        masks = [masks_folder_path+name for name in os.listdir(masks_folder_path)]\n","        return images, masks\n"],"metadata":{"id":"_X6H6uQVrZt-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ToTensor(object):\n","    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n","\n","    def __call__(self, sample):\n","        image, mask = sample['image'], sample['mask']\n","\n","        # swap color axis because\n","        # numpy image: H x W x C\n","        # torch image: C X H X W\n","        image = image.transpose((2, 0, 1))\n","        mask = np.expand_dims(mask, axis=-1)\n","        mask = mask.transpose((2, 0, 1))\n","        #print(image)\n","        return {'image': torch.from_numpy(image),\n","                'mask': torch.from_numpy(mask)}"],"metadata":{"id":"g2tYXcGars9S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bLjg6z5dsHkP"},"source":["## 4.8 DataLoaders for train and validation"]},{"cell_type":"markdown","metadata":{"id":"-ncSQth8sHkQ"},"source":["Load dataset class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X3b1FFjAsHkR"},"outputs":[],"source":["bowl_train = BowlDataset(\"/content/bowl_dataset-new_data/content/bowl_dataset/new_data/train/image/\", \"/content/bowl_dataset-new_data/content/bowl_dataset/new_data/train/mask/\",transform = ToTensor())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rcVZtFqjsHkR"},"outputs":[],"source":["train_dataloader = DataLoader(bowl_train, batch_size=config['batch_size'],\n","                        shuffle=True, num_workers= config['num_workers'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0zhz4fVsHkR"},"outputs":[],"source":["bowl_valid = BowlDataset(\"/content/bowl_dataset-new_data/content/bowl_dataset/new_data/valid/image/\", \"/content/bowl_dataset-new_data/content/bowl_dataset/new_data/valid/mask/\",transform = ToTensor())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ggi47A95sHkR"},"outputs":[],"source":["valid_dataloader = DataLoader(bowl_valid, batch_size=config['batch_size'],\n","                        shuffle=True, num_workers=config['num_workers'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmfF_YotsHkR"},"outputs":[],"source":["bowl_test = BowlDataset(\"/content/bowl_dataset-new_data/content/bowl_dataset/new_data/test/image/\", \"/content/bowl_dataset-new_data/content/bowl_dataset/new_data/test/mask/\",transform = ToTensor())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTQSTVp3sHkR"},"outputs":[],"source":["test_dataloader = DataLoader(bowl_test, batch_size=config['batch_size'],\n","                        shuffle=True, num_workers=config['num_workers'])"]},{"cell_type":"markdown","metadata":{"id":"QEwJfff1Brk5"},"source":["# 5 Model Architecture"]},{"cell_type":"markdown","metadata":{"id":"tSxHJ0b9AuBR"},"source":["## 5.1 conv block"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"h-dsRMG3iUCC","executionInfo":{"status":"ok","timestamp":1666016480621,"user_tz":-180,"elapsed":19,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["class conv_block(nn.Module):\n","    def __init__(self, filters , input_channels):\n","        super().__init__()\n","        self.conv_layer1 = nn.Conv2d(input_channels, filters, 3, padding='same')\n","        self.BN_layer1 = nn.BatchNorm2d(filters)\n","        self.ReLu1 = nn.ReLU(inplace=True)\n","\n","        self.conv_layer2 = nn.Conv2d(filters, filters, 3, padding='same')\n","        self.BN_layer2 = nn.BatchNorm2d(filters)\n","        self.ReLu2 = nn.ReLU(inplace=True)\n","\n","        self.SE = SqueezeExcitation(input_channels = filters, squeeze_channels = filters//config['squeeze_ratio'])\n","\n","    def forward(self, x):\n","\n","         z = self.conv_layer1(x)\n","         z = self.BN_layer1(z)\n","         z = self.ReLu1(z)\n","         \n","         z = self.conv_layer2(z)\n","         z = self.BN_layer2(z)\n","         z = self.ReLu2(z)\n","\n","         z = self.SE(z)\n","\n","         return z\n"]},{"cell_type":"markdown","metadata":{"id":"1O0oZI1qBDQY"},"source":["## 5.2 encoder1"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"SgtUIepwkFjn","executionInfo":{"status":"ok","timestamp":1666016480621,"user_tz":-180,"elapsed":19,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["class encoder1(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.VGG_19 = vgg19(pretrained= True, progress = True)\n","        #self.output_shape = self.VGG_19.features[35].register_forward_hook(output.detach())\n","\n","    def forward(self, x):\n","        skip_connections = {}\n","        def get_activation(name):\n","            ''' function that stores layers outputs in dict named skip_connections '''\n","            def hook(model, input, output):\n","                skip_connections[name]=output.detach()\n","            return hook\n","\n","        skip_connections_layer = [3,8,17,26,35] # Middle outputs of VGG. \n","        for num,layer in enumerate(skip_connections_layer):\n","            self.VGG_19.features[layer].register_forward_hook(get_activation('ConvBlock'+str(num)))\n","\n","        self.VGG_19(x)\n","\n","        encoder1_output = skip_connections['ConvBlock4']\n","        del skip_connections['ConvBlock4']\n","\n","\n","        return  encoder1_output, skip_connections         \n"]},{"cell_type":"markdown","metadata":{"id":"H6DEyzwxBJVo"},"source":["## 5.3 ASPP"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"YGSxccopstfH","executionInfo":{"status":"ok","timestamp":1666016480622,"user_tz":-180,"elapsed":19,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["\n","class ASPP(nn.Module):\n","\n","    ''' 512 is the channels of encoder1 output '''\n","    def __init__(self,shape,filter):\n","        super().__init__()\n","        self.AvgPool1 = nn.AvgPool2d(kernel_size=(shape[2], shape[3]))\n","        self.conv_layer1 = nn.Conv2d(shape[1], filter, kernel_size=1, padding=1)\n","        self.BN_layer1 = nn.BatchNorm2d(filter)\n","        self.ReLu1 = nn.ReLU(inplace=True)\n","        self.UpSampling = nn.Upsample((shape[2], shape[3]) , mode = 'bilinear')\n","\n","        self.conv_layer2 = nn.Conv2d(shape[1], filter, kernel_size=1 , dilation=1, padding='same' , bias =\"False\")\n","        self.BN_layer2 = nn.BatchNorm2d(filter)\n","        self.ReLu2 = nn.ReLU(inplace=True)\n","\n","        self.conv_layer3 = nn.Conv2d(shape[1], filter, kernel_size=3 , dilation=6, padding='same', bias =\"False\")\n","        self.BN_layer3 = nn.BatchNorm2d(filter)\n","        self.Relu3 = nn.ReLU(inplace=True)\n","\n","        self.conv_layer4 = nn.Conv2d(shape[1], filter, kernel_size=3 , dilation=12, padding='same', bias =\"False\")\n","        self.BN_layer4 = nn.BatchNorm2d(filter)\n","        self.Relu4 = nn.ReLU(inplace=True)\n","\n","        self.conv_layer5 = nn.Conv2d(shape[1], filter, kernel_size=3 , dilation=18, padding='same', bias =\"False\")\n","        self.BN_layer5  = nn.BatchNorm2d(filter)\n","        self.Relu5 = nn.ReLU(inplace=True)\n","\n","        self.conv_layer6 = nn.Conv2d(filter*5, filter, kernel_size=1 , dilation=1, padding='same', bias =\"False\")\n","        self.BN_layer6 = nn.BatchNorm2d(filter)\n","        self.Relu6 = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","\n","        y1 = self.AvgPool1(x) ## SUS\n","        y1 = self.conv_layer1(y1)\n","        y1 = self.BN_layer1(y1)\n","        y1 = self.ReLu1(y1)\n","        y1 = self.UpSampling(y1)\n","\n","        y2 = self.conv_layer2(x)\n","        y2 = self.BN_layer2(y2)\n","        y2 = self.ReLu2(y2)\n","\n","        y3 = self.conv_layer3(x)\n","        y3 = self.BN_layer3(y3)\n","        y3 = self.Relu3(y3)\n","\n","        y4 = self.conv_layer4(x)\n","        y4 = self.BN_layer4(y4)\n","        y4 = self.Relu4(y4)\n","\n","        y5 = self.conv_layer5(x)\n","        y5 = self.BN_layer5(y5)\n","        y5 = self.Relu5(y5)\n","\n","        y = torch.cat((y1,y2,y3,y4,y5),1)\n","\n","        y = self.conv_layer6(y)\n","        y = self.BN_layer6(y)\n","        y = self.Relu6(y)        \n","        \n","        return y  "]},{"cell_type":"markdown","metadata":{"id":"DMP1E9U0E5Zu"},"source":["## 5.4 Attention block"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"5IGbHpGYE-Et","executionInfo":{"status":"ok","timestamp":1666016480622,"user_tz":-180,"elapsed":19,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["class Attention_block(nn.Module):\n","    def __init__(self,F_g,F_l,F_int):\n","        super().__init__()\n","        self.W_g = nn.Sequential(\n","            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(F_int)\n","            )\n","        \n","        self.W_x = nn.Sequential(\n","            nn.Conv2d(F_l, F_int, kernel_size=1,stride=2,padding=0,bias=True),\n","            nn.BatchNorm2d(F_int)\n","        )\n","\n","        self.psi = nn.Sequential(\n","            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(1),\n","            nn.Sigmoid(),\n","            nn.Upsample(scale_factor = 2 , mode = 'bilinear')\n","        )\n","        \n","        self.relu = nn.ReLU(inplace=True)\n","        \n","    def forward(self,g,xt):\n","        g1 = self.W_g(g)\n","        x1 = self.W_x(xt)\n","        psi = self.relu(g1+x1)\n","        psi = self.psi(psi)\n","\n","        return xt*psi\n"]},{"cell_type":"markdown","metadata":{"id":"yABtPT1rBR9J"},"source":["## 5.5 decoder1"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"VkzhStwJ3_9Z","executionInfo":{"status":"ok","timestamp":1666016480622,"user_tz":-180,"elapsed":18,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["\n","class decoder1(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ConvBlock1 = conv_block(filters = 256 , input_channels = 576)\n","        self.ConvBlock2 = conv_block(filters = 128 , input_channels = 512)\n","        self.ConvBlock3 = conv_block(filters = 64 , input_channels = 256)\n","        self.ConvBlock4 = conv_block(filters = 32 , input_channels = 128)\n","\n","        self.UpSampling1 = nn.Upsample(scale_factor = 2 , mode = 'bilinear')\n","        self.UpSampling2 = nn.Upsample(scale_factor = 2 , mode = 'bilinear')\n","        self.UpSampling3 = nn.Upsample(scale_factor = 2 , mode = 'bilinear')\n","        self.UpSampling4 = nn.Upsample(scale_factor = 2 , mode = 'bilinear')\n","\n","        self.Att1 = Attention_block(F_g=64,F_l=512,F_int=512)\n","        self.Att2 = Attention_block(F_g=256,F_l=256,F_int=256)\n","        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=128)\n","        self.Att4 = Attention_block(F_g=64,F_l=64,F_int=64)\n","\n","        \n","\n","    def forward(self, x , skip_connections):\n","        #print(x.shape)\n","        #print(skip_connections['ConvBlock3'].shape)\n","        xt3 = self.Att1(g=x, xt=skip_connections['ConvBlock3']) \n","        x = self.UpSampling1(x) ### SUS\n","        #xt3 = self.Att1(g=x, xt=skip_connections['ConvBlock3']) \n","        x = torch.cat((x, xt3),1)\n","        x = self.ConvBlock1(x) ##\n","\n","        xt2 = self.Att2(g=x, xt = skip_connections['ConvBlock2'] )\n","        x = self.UpSampling2(x) ### SUS\n","        #xt2 = self.Att2(g=x, xt = skip_connections['ConvBlock2'] )\n","        x = torch.cat((x, xt2),1)\n","        x = self.ConvBlock2(x)\n","\n","        xt1 = self.Att3(g=x, xt = skip_connections['ConvBlock1'] )\n","        x = self.UpSampling3(x) ### SUS\n","        #xt1 = self.Att3(g=x, xt = skip_connections['ConvBlock1'] )\n","        x = torch.cat((x, xt1),1)\n","        x = self.ConvBlock3(x)\n","\n","        xt0 = self.Att4(g=x, xt = skip_connections['ConvBlock0'] )\n","        x = self.UpSampling4(x) ### SUS\n","        #xt0 = self.Att4(g=x, xt = skip_connections['ConvBlock0'] )\n","        x = torch.cat((x, xt0),1)\n","        z = self.ConvBlock4(x)\n","\n","        return z\n"]},{"cell_type":"markdown","metadata":{"id":"KwjEHxkQBXLg"},"source":["## 5.6 output block"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"_0_jNKFlFS3A","executionInfo":{"status":"ok","timestamp":1666016481705,"user_tz":-180,"elapsed":1100,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["\n","class output_block(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.conv_layer = nn.Conv2d(32,1,kernel_size=1, padding='same')\n","        self.sig = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.conv_layer(x)\n","        z = self.sig(x)\n","\n","        return z\n"]},{"cell_type":"markdown","metadata":{"id":"wUI-MMQQBadR"},"source":["## 5.7 encoder2"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"Oz-Z6wZFsFNE","executionInfo":{"status":"ok","timestamp":1666016481706,"user_tz":-180,"elapsed":11,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["\n","class encoder2(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ConvBlock1 = conv_block(filters = 32 , input_channels = 3)\n","        self.ConvBlock2 = conv_block(filters = 64 , input_channels = 32)\n","        self.ConvBlock3 = conv_block(filters = 128 , input_channels = 64)\n","        self.ConvBlock4 = conv_block(filters = 256 , input_channels = 128)\n","\n","        self.MaxPooling1 = nn.MaxPool2d(kernel_size=2)\n","        self.MaxPooling2 = nn.MaxPool2d(kernel_size=2)\n","        self.MaxPooling3 = nn.MaxPool2d(kernel_size=2)\n","        self.MaxPooling4 = nn.MaxPool2d(kernel_size=2)\n","\n","        self.drop1 = nn.Dropout(p=0.25, inplace = False)\n","        self.drop2 = nn.Dropout(p=0.5, inplace = False)\n","        self.drop3 = nn.Dropout(p=0.5, inplace = False)\n","        self.drop4 = nn.Dropout(p=0.5, inplace = False)\n","\n","    def forward(self, x):\n","      # add dropout after pooling\n","        skip_connections = {}\n","\n","        x = self.ConvBlock1(x)\n","        skip_connections['encoder2Block0']=x\n","        x = self.MaxPooling1(x)\n","        x = self.drop1(x)\n","\n","        x = self.ConvBlock2(x)\n","        skip_connections['encoder2Block1']=x\n","        x = self.MaxPooling2(x)\n","        x = self.drop2(x)\n","\n","        x = self.ConvBlock3(x)\n","        skip_connections['encoder2Block2']=x\n","        x = self.MaxPooling3(x)\n","        x = self.drop3(x)\n","\n","        x = self.ConvBlock4(x)\n","        skip_connections['encoder2Block3']=x\n","        z = self.MaxPooling4(x)\n","        z = self.drop4(z)\n","\n","        return  z, skip_connections     \n"]},{"cell_type":"markdown","metadata":{"id":"MOYwz6uOBdOZ"},"source":["## 5.8 decoder2"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"nh5MqqFvu-_S","executionInfo":{"status":"ok","timestamp":1666016481706,"user_tz":-180,"elapsed":10,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["class decoder2(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ConvBlock1 = conv_block(filters = 256 , input_channels = 832)\n","        self.ConvBlock2 = conv_block(filters = 128 , input_channels = 640)\n","        self.ConvBlock3 = conv_block(filters = 64 , input_channels = 320)\n","        self.ConvBlock4 = conv_block(filters = 32 , input_channels = 160)\n","\n","        self.UpSampling1 = nn.Upsample(scale_factor = 2 , mode = 'bilinear')\n","        self.UpSampling2 = nn.Upsample(scale_factor = 2 , mode = 'bilinear')\n","        self.UpSampling3 = nn.Upsample(scale_factor = 2 , mode = 'bilinear')\n","        self.UpSampling4 = nn.Upsample(scale_factor = 2 , mode = 'bilinear')\n","        \n","        self.Att1_enc1 = Attention_block(F_g=64,F_l=512,F_int=512)\n","        self.Att2_enc1 = Attention_block(F_g=256,F_l=256,F_int=256)\n","        self.Att3_enc1 = Attention_block(F_g=128,F_l=128,F_int=128)\n","        self.Att4_enc1 = Attention_block(F_g=64,F_l=64,F_int=64)\n","\n","        self.Att1_enc2 = Attention_block(F_g=64,F_l=256,F_int=256)\n","        self.Att2_enc2 = Attention_block(F_g=256,F_l=128,F_int=128)\n","        self.Att3_enc2 = Attention_block(F_g=128,F_l=64,F_int=64)\n","        self.Att4_enc2 = Attention_block(F_g=64,F_l=32,F_int=32)\n","\n","        self.drop1 = nn.Dropout(p=0.5, inplace = False)\n","        self.drop2 = nn.Dropout(p=0.5, inplace = False)\n","        self.drop3 = nn.Dropout(p=0.5, inplace = False)\n","        self.drop4 = nn.Dropout(p=0.5, inplace = False)\n","\n","\n","    def forward(self, x , skip_1, skip_2):\n","      #add drop out after concats\n","        \n","        xt3_enc1 = self.Att1_enc1(g=x, xt=skip_1['ConvBlock3']) \n","        xt3_enc2 = self.Att1_enc2(g=x, xt=skip_2['encoder2Block3']) \n","        x = self.UpSampling1(x) ### SUS\n","        #xt3_enc1 = self.Att1_enc1(g=x, xt=skip_1['ConvBlock3']) \n","        #xt3_enc2 = self.Att1_enc2(g=x, xt=skip_2['encoder2Block3']) \n","        x = torch.cat((x, xt3_enc1,xt3_enc2),1)\n","        x = self.drop1(x)\n","        x = self.ConvBlock1(x)\n","\n","        xt2_enc1 = self.Att2_enc1(g=x, xt = skip_1['ConvBlock2'] )\n","        xt2_enc2 = self.Att2_enc2(g=x, xt=skip_2['encoder2Block2']) \n","        x = self.UpSampling2(x) ### SUS\n","        #xt2_enc1 = self.Att2_enc1(g=x, xt = skip_1['ConvBlock2'] )\n","        #xt2_enc2 = self.Att2_enc2(g=x, xt=skip_2['encoder2Block2']) \n","        x = torch.cat((x, xt2_enc1,xt2_enc2),1)\n","        x = self.drop2(x)\n","        x = self.ConvBlock2(x)\n","\n","        xt1_enc1 = self.Att3_enc1(g=x, xt = skip_1['ConvBlock1'] )\n","        xt1_enc2 = self.Att3_enc2(g=x, xt=skip_2['encoder2Block1']) \n","        x = self.UpSampling3(x) ### SUS\n","        #xt1_enc1 = self.Att3_enc1(g=x, xt = skip_1['ConvBlock1'] )\n","        #xt1_enc2 = self.Att3_enc2(g=x, xt=skip_2['encoder2Block1']) \n","        x = torch.cat((x, xt1_enc1,xt1_enc2),1)\n","        x = self.drop3(x)\n","        x = self.ConvBlock3(x)\n","\n","        xt0_enc1 = self.Att4_enc1(g=x, xt = skip_1['ConvBlock0'] )\n","        xt0_enc2 = self.Att4_enc2(g=x, xt=skip_2['encoder2Block0']) \n","        x = self.UpSampling4(x) ### SUS\n","        #xt0_enc1 = self.Att4_enc1(g=x, xt = skip_1['ConvBlock0'] )\n","        #xt0_enc2 = self.Att4_enc2(g=x, xt=skip_2['encoder2Block0'])\n","        x = torch.cat((x, xt0_enc1,xt0_enc2),1)\n","        x = self.drop4(x)\n","        z = self.ConvBlock4(x)\n","\n","        return z"]},{"cell_type":"markdown","metadata":{"id":"-8gE8j-1Bhi4"},"source":["## 5.9 DoubleAU-Net Class"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"EbdqiNvU3kju","executionInfo":{"status":"ok","timestamp":1666016481706,"user_tz":-180,"elapsed":9,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["## removed the //2 at inputs sizes\n","## removed resized input at the begining and at the end\n","\n","class DoubleUNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.encoder1 = encoder1()\n","\n","        if config['use_interpolation'] == False:\n","          self.ASPP1 = ASPP(shape = [config['batch_size'], 512, config['input_h']//16, config['input_w']//16] , filter = 64) ## dividing by 16 is because of x4 MaxPooiling in each encoder\n","        elif config['use_interpolation'] == True:  \n","          self.ASPP1 = ASPP(shape = [config['batch_size'], 512, config['input_h']//2//16, config['input_w']//2//16] , filter = 64) ## In case we want to use interpolation\n","\n","        self.decoder1 = decoder1()\n","        self.outblock1 = output_block()\n","        self.encoder2 = encoder2()\n","\n","        if config['use_interpolation'] == False:\n","          self.ASPP2 = ASPP(shape = [config['batch_size'], 256, config['input_h']//16, config['input_w']//16] , filter = 64) ## dividing by 16 is because of x4 MaxPooiling in each encoder\n","        elif config['use_interpolation'] == True:\n","          self.ASPP2 = ASPP(shape = [config['batch_size'], 256, config['input_h']//2//16, config['input_w']//2//16] , filter = 64) ## In case we want to use interpolation\n","\n","        self.decoder2 = decoder2()\n","        self.outblock2 = output_block()\n","    \n","    def forward(self,input):\n","        if config['use_interpolation'] == False:\n","          resized_input = input\n","        elif config ['use_interpolation'] == True:\n","          resized_input = F.interpolate(input,(config['input_h']//2,config['input_w']//2)) # In case we want to use interpolation\n","\n","        encoder1_output,skip_connections1 = self.encoder1(resized_input)\n","        y1 = self.ASPP1(encoder1_output)\n","\n","        decoder1_output = self.decoder1(y1,skip_connections1)\n","        output1= self.outblock1(decoder1_output)\n","\n","        mul = output1*resized_input\n","\n","        encoder2_output, skip_connections2 = self.encoder2(mul)\n","        y2 = self.ASPP2 (encoder2_output)\n","\n","        decoder2_output = self.decoder2(y2,skip_connections1,skip_connections2)\n","\n","        output2= self.outblock2(decoder2_output)\n","\n","        if config['use_interpolation'] == False:\n","          resized_output2 = output2\n","        elif config['use_interpolation'] == True:\n","          resized_output2 = F.interpolate(output2,(config['input_h'],config['input_w'])) # In case we want to use interpolation\n","\n","        #print (output2.shape)\n","        return resized_output2"]},{"cell_type":"markdown","metadata":{"id":"eACP99VJ1_WE"},"source":["# 6 Metrics"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"SFd2pCK9V1CJ","executionInfo":{"status":"ok","timestamp":1666016481707,"user_tz":-180,"elapsed":9,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["# need to see if we want to do this method on 1 sample or batch of samples, if so no need for dim\n","def dice_coef(y_true, y_pred):\n"," \n","    y_true = nn.Flatten()(y_true) #flatten all dimensions for the model output except the first one (the batch dimention)\n","    y_pred = nn.Flatten()(y_pred) #flatten all dimensions for the groud truth except the first one (the batch dimention)\n","    #y_pred = torch.round(y_pred)\n","\n","    intersection = torch.sum(y_true * y_pred,1) # we get (num of element in batch) answers, one for each true and pred in betch.\n","    return (2. * intersection + config['smooth']) / (torch.sum(y_true,1) + torch.sum(y_pred,1) + config['smooth'])\n","\n","\n","def dice_loss(y_true, y_pred):\n","\n","    return 1.0 - dice_coef(y_true, y_pred)\n","\n","def iou(y_true, y_pred):\n","    with torch.no_grad():\n","      y_true = nn.Flatten()(y_true) #flatten all dimensions for the model output except the first one (the batch dimention)\n","      y_pred = nn.Flatten()(y_pred) #flatten all dimensions for the groud truth except the first one (the batch dimention)\n","      y_pred = torch.round(y_pred)\n","\n","      intersection = torch.sum(y_true * y_pred,1) # we get (num of element in batch) answers, one for each true and pred in betch.\n","      union = torch.sum(y_true,1) + torch.sum(y_pred,1) - intersection\n","      x = (intersection + config['smooth']) / (union + config['smooth'])\n","      #x = x.astype(np.float32)\n","      return x\n","\n","def bce_dice_loss(y_true, y_pred):\n","\n","    return F.binary_cross_entropy(y_pred, y_true) + dice_loss(y_true, y_pred)\n","\n","def focal_loss(y_true, y_pred):\n","    alpha=0.25\n","    gamma=2\n","\n","    def focal_loss_with_logits(logits, targets, alpha, gamma, y_pred):\n","        weight_a = alpha * (1 - y_pred) ** gamma * targets\n","        weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n","        return (torch.log(1+torch.exp(-torch.abs(logits))) + F.relu(-logits)) * (weight_a + weight_b) + logits * weight_b\n","\n","    y_pred = torch.clamp(y_pred, 1e-07, 1 - 1e-07)\n","    logits = torch.log(y_pred / (1 - y_pred))\n","    loss = focal_loss_with_logits(logits=logits, targets=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n","    # or reduce_sum and/or axis=-1\n","    return loss - torch.mean(loss) \n","    #return tf.reduce_mean(loss)\n","\n","def calculate_prec_rec(y_true, y_pred):\n","    with torch.no_grad():\n","      y_true = nn.Flatten()(y_true) #flatten all dimensions for the model output except the first one (the batch dimention)\n","      y_pred = nn.Flatten()(y_pred) #flatten all dimensions for the groud truth except the first one (the batch dimention)\n","\n","      #y_true = torch.round(y_true)\n","      y_pred = torch.round(y_pred)\n","\n","      intersection = torch.sum(y_true * y_pred,1) # we get (num of element in batch) answers, one for each true and pred in betch.\n","      tp = torch.sum(y_pred * y_true,1)  # TP\n","      fp = torch.sum(y_pred *(1-y_true),1)  # FP\n","      fn = torch.sum(((1 - y_pred) * y_true),1)  # FN\n","      tn = torch.sum(((1 - y_pred) * (1 - y_true)),1)  # TN\n","\n","\n","      precision = (tp + config['smooth']) / (tp + fp + config['smooth'])\n","      recall = (tp + config['smooth']) / (tp + fn + config['smooth'])\n","\n","\n","      return  precision, recall\n"]},{"cell_type":"markdown","metadata":{"id":"C1tzpPwNYV40"},"source":["# 7 Training"]},{"cell_type":"markdown","metadata":{"id":"blDzh6WlrwqZ"},"source":["## 7.1 Test function"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"X6-lUnOEYInY","executionInfo":{"status":"ok","timestamp":1666016481707,"user_tz":-180,"elapsed":9,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["def test(model,valid_data,output_file_path):\n","    model.eval()\n","    valid_loss = 0\n","    mPrecision=0\n","    mRecall=0\n","    mIOU=0\n","    avg_batch_valid_DSC=0\n","    \n","    num_batches = len(valid_data)\n","    with torch.no_grad():\n","        for batch_idx,batch in enumerate(valid_data):\n","            # Getting the batch data:\n","            x = batch['image'].to(device) #GPU\n","            y = batch['mask'].to(device) # GPU\n","\n","            # Getting predictions:\n","            y_pred = model(x)\n","\n","            if config['dataset']=='CVC':\n","              batch_loss = bce_dice_loss(y,y_pred)\n","            elif config['dataset']=='bowl':\n","              batch_loss = dice_loss(y,y_pred)\n","              \n","            batch_valid_DSC = dice_coef(y,y_pred)\n","\n","            #print(batch_loss)\n","            avg_batch_valid_DSC += batch_valid_DSC.sum()/(len(batch_valid_DSC))\n","            loss = batch_loss.sum()/(len(batch_loss))\n","            valid_loss+=loss #sums up all avg batch losses\n","\n","            # Calculating Accuracy:\n","            precision, recall = calculate_prec_rec(y, y_pred)\n","            pred_iou = iou(y, y_pred)\n","\n","            mPrecision+=precision.sum()/(len(precision)) #mean precision of a batch and sums them up\n","            mRecall+=recall.sum()/(len(recall)) #mean recall of a batch and sums them up\n","            mIOU+=pred_iou.sum()/(len(pred_iou)) #mean IOU of a batch and sums them up\n","\n","    valid_loss /= num_batches\n","    valid_DSC = avg_batch_valid_DSC / num_batches\n","    print_both('\\n~~~~~~~~~~~~~~~~~ Test Loss: {:.4f} ~~~~~~~~~~~~~~~~~\\n'.format(valid_loss),output_file_path = output_file_path)\n","    print_both('mean Precision:{}   |    mean Recall:{}   |    mIOU:{}    |   DSC:{}\\n'.format(mPrecision/ num_batches, mRecall/ num_batches, mIOU/ num_batches, valid_DSC),output_file_path = output_file_path)\n","    \n","    return valid_loss.item(), valid_DSC.item(), (mPrecision/ num_batches).item(), (mRecall/ num_batches).item(), (mIOU/ num_batches).item()\n"]},{"cell_type":"markdown","metadata":{"id":"fUc5JjxBsIkx"},"source":["## 7.2 Train function"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"78mrAUjpRU-m","executionInfo":{"status":"ok","timestamp":1666016481707,"user_tz":-180,"elapsed":8,"user":{"displayName":"Roe Barlev","userId":"07253921536425016556"}}},"outputs":[],"source":["def train(model,train_data ,valid_data,test_data,epochs = config['epochs']):\n","\n","    # datetime object containing current date and time\n","    now = datetime.now()\n","    # dd/mm/YY H:M:S\n","    dt_string = now.strftime(\"%d.%m.%Y %H:%M:%S\")\n","    create_dir(config['output_path']+str(dt_string))\n","\n","    #optimizer:\n","    if config['dataset']=='CVC':\n","      opt = NAdam(params=model.parameters() ,lr=config['lr'],eps=config['eps'])\n","    elif config['dataset']=='bowl':\n","      opt = Adam(params=model.parameters() ,lr=config['lr'],eps=config['eps'])\n","\n","    # scheduler:\n","    scheduler = lr_scheduler.ReduceLROnPlateau(opt, 'min', factor = config['scheduler_reduce_lr_factor'], patience = config['scheduler_patience'])\n","     #set model mode:\n","    model.train()\n","\n","    # define variables:\n","    num_batches = len(train_data)\n","\n","    output_file_path = config['output_path']+str(dt_string)+\"/output.txt\" #open file to save all prints to it\n","\n","    print_both(model,output_file_path=output_file_path)\n","    print_both('\\nTrain started at:{}\\n'.format(dt_string),output_file_path=output_file_path)\n","    print_both('\\Model architecture:{}\\n'.format(config['notebook_name']),output_file_path=output_file_path)\n","\n","    #save config to txt file\n","    dict_to_txt(dict_ = config , output_file_path = config['output_path']+str(dt_string)+'/config.txt')\n","\n","    best_epoch_stats = {}\n","    train_loss_epoch_arr = []\n","    train_mPrecision_arr = []\n","    train_mRecall_arr = []\n","    train_mIOU_arr = []\n","    train_DSC_arr =[]\n","\n","    valid_loss_epoch_arr = []\n","    valid_mPrecision_arr = []\n","    valid_mRecall_arr = []\n","    valid_mIOU_arr = []\n","    valid_DSC_arr=[]\n","\n","    best_valid_loss = 100\n","    \n","    # Early stopping parameters\n","    last_loss = 100\n","    ES_patience = config['early_stopping_patience']\n","    triggertimes = 0\n","\n","    print_both ('~~~~~~~~~~~ START OF TRAINING ~~~~~~~~~~~\\n',output_file_path=output_file_path)\n","\n","    #training loop:\n","    for epoch in range(epochs):\n","        print_both(' ---------Starting EPOCH {}---------\\n '.format(epoch),output_file_path=output_file_path)\n","        train_loss=0\n","        mPrecision=0\n","        mRecall=0\n","        mIOU=0\n","        train_DSC=0\n","        model.train()\n","\n","        if (epoch ==10):\n","          config[\"lr\"] = 1e-5\n","\n","\n","        for batch_idx,batch in enumerate(train_data): \n","            # Getting the batch data:\n","            x = batch['image'].to(device) #GPU\n","            y = batch['mask'].to(device) # GPU\n","\n","            # Getting predictions:\n","            y_pred = model(x)\n","            #y_pred>0.5\n","\n","            # Calculating loss:\n","            if config['dataset']=='CVC':\n","              batch_loss = bce_dice_loss(y,y_pred)\n","            elif config['dataset']=='bowl':\n","              batch_loss = dice_loss(y,y_pred)\n","\n","              \n","            batch_train_DSC = dice_coef(y,y_pred)\n","            \n","\n","            #print(batch_loss)\n","            train_DSC += batch_train_DSC.sum()/(len(batch_train_DSC))\n","            loss = batch_loss.sum()/(len(batch_loss)) #sum the batch losses and devide by the number of samples in batch, mean loss \n","            train_loss+=loss.item()\n","\n","            # Calculating Accuracy:\n","            precision, recall = calculate_prec_rec(y, y_pred) #tensors with size of batch, each element represent precision (and) recall for each image and prediction\n","            pred_iou = iou(y, y_pred) #tensor with size of batch, each element represent iou for each image and prediction\n","            \n","            mPrecision+=precision.sum()/(len(precision)) #mean precision of a batch and sums them up\n","            mRecall+=recall.sum()/(len(recall)) #mean recall of a batch and sums them up\n","            mIOU+=pred_iou.sum()/(len(pred_iou)) #mean IOU of a batch and sums them up\n","\n","            # Back propagation:\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","\n","            num_images_vs_batch = batch_idx * len(x) #batch number mult. number of images in a batch\n","            total_num_images = len(train_data)*len(x) #num of batches nult. num of umages in a batch\n","            batch_ratio = batch_idx/ len(train_data)\n","            # print every 100 batches\n","            if batch_idx % 100 == 0:\n","                print_both('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\n'.format(epoch, num_images_vs_batch, total_num_images ,100. * batch_ratio, loss.item()),output_file_path=output_file_path)\n","\n","        epoch_avg_loss = train_loss / num_batches  #take the total losses per batch and devide by the number of batches \n","        epoch_avg_DSC = train_DSC.item() / num_batches\n","\n","        train_mPrecision =   mPrecision.item()/ num_batches\n","        train_mRecall = mRecall.item()/ num_batches\n","        train_mIOU = mIOU.item()/ num_batches\n","\n","        print_both('~~~~~~~~~~~ Epoch: {} Average loss: {:.4f} ~~~~~~~~~~~\\n'.format(epoch, epoch_avg_loss),output_file_path=output_file_path)\n","        print_both('mean Precision:{}   |    mean Recall:{}   |    mIOU:{}    |   DSC:{}\\n'.format(train_mPrecision, train_mRecall, train_mIOU, epoch_avg_DSC),output_file_path=output_file_path)\n","\n","        end_time = datetime.now()\n","        # dd/mm/YY H:M:S\n","        end_time_dt = end_time.strftime(\"%d.%m.%Y %H:%M:%S\")\n","        print_both('\\nEpoch ended at:{}\\n'.format(end_time_dt),output_file_path=output_file_path)\n","\n","        # validation:\n","        valid_loss, valid_DSC, valid_mPrecision, valid_mRecall, valid_mIOU  = test(model,valid_data,output_file_path) \n","\n","\n","        #save train and validation params vs epochs for plot later on\n","        train_loss_epoch_arr.append(epoch_avg_loss)\n","        save_list(train_loss_epoch_arr,output_path = config['output_path']+str(dt_string)+'/train_loss_arr.pkl')\n","\n","        train_mPrecision_arr.append(train_mPrecision)\n","        save_list(train_mPrecision_arr,output_path = config['output_path']+str(dt_string)+'/train_mPrecision_arr.pkl')\n","\n","        train_mRecall_arr.append(train_mRecall)\n","        save_list(train_mRecall_arr,output_path = config['output_path']+str(dt_string)+'/train_mRecall_arr.pkl')\n","\n","        train_mIOU_arr.append(train_mIOU)\n","        save_list(train_mIOU_arr,output_path = config['output_path']+str(dt_string)+'/train_mIOU_arr.pkl')\n","\n","        train_DSC_arr.append(epoch_avg_DSC)\n","        save_list(train_DSC_arr,output_path = config['output_path']+str(dt_string)+'/train_DSC_arr.pkl')\n","\n","        valid_loss_epoch_arr.append(valid_loss)\n","        save_list(valid_loss_epoch_arr,output_path = config['output_path']+str(dt_string)+'/valid_loss_epoch_arr.pkl')\n","\n","        valid_mPrecision_arr.append(valid_mPrecision)\n","        save_list(valid_mPrecision_arr,output_path = config['output_path']+str(dt_string)+'/valid_mPrecision_arr.pkl')\n","\n","        valid_mRecall_arr.append(valid_mRecall)\n","        save_list(valid_mRecall_arr,output_path = config['output_path']+str(dt_string)+'/valid_mRecall_arr.pkl')\n","\n","        valid_mIOU_arr.append(valid_mIOU)\n","        save_list(valid_mIOU_arr,output_path = config['output_path']+str(dt_string)+'/valid_mIOU_arr.pkl')\n","\n","        valid_DSC_arr.append(valid_DSC)\n","        save_list(valid_DSC_arr,output_path = config['output_path']+str(dt_string)+'/valid_DSC_arr.pkl')\n","\n","\n","        torch.save (model.state_dict(),config['output_path']+str(dt_string)+'/DoubleUNet_last_checkpoint.pth')\n","\n","        # saving model and stats to output folder:\n","        if (valid_loss<best_valid_loss):\n","          torch.save (model.state_dict(),config['output_path']+str(dt_string)+'/DoubleUNet.pth')\n","          best_valid_loss = valid_loss \n","          best_epoch_stats = {'epoch': epoch,\n","                              'Train mPrecision': train_mPrecision ,\n","                              'Train mRecall': train_mRecall,\n","                              'Train mIOU': train_mIOU,\n","                              'Train loss': epoch_avg_loss,\n","                              'Train DSC' : epoch_avg_DSC,\n","                              'Valid mPrecision': valid_mPrecision ,\n","                              'Valid mRecall': valid_mRecall,\n","                              'Valid mIOU': valid_mIOU,\n","                              'Valid loss': valid_loss,\n","                              'Valid DSC' : valid_DSC,\n","                              }\n","          #write best_epoch_stats dict to txt file\n","          dict_to_txt(dict_ = best_epoch_stats , output_file_path = config['output_path']+str(dt_string)+'/best_epoch_stats.txt')\n","          \n","        \n","        # reduce lr plateau\n","        scheduler.step(valid_loss)\n","\n","        # Early stopping\n","        current_loss = valid_loss\n","\n","        if current_loss > last_loss:\n","            trigger_times += 1\n","            print_both('Early stopping Trigger Times:\\n', trigger_times,output_file_path=output_file_path)\n","\n","            if trigger_times >= ES_patience:\n","                print_both('Early stopping!\\nStart to final test process.\\n',output_file_path=output_file_path)\n","                return model\n","\n","        else:\n","            print_both('trigger times: 0\\n',output_file_path=output_file_path)\n","            trigger_times = 0\n","\n","        last_loss = current_loss\n","\n","    return model \n","\n","            "]},{"cell_type":"markdown","metadata":{"id":"CjtX6mel57Rf"},"source":["## 7.3 Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ISgnNjgKer23"},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","DoubleUNet_model = DoubleUNet().to(device)\n","#print(DoubleUNet_model)\n","\n","train(DoubleUNet_model,train_dataloader,valid_dataloader,test_dataloader,epochs=config['epochs'])"]},{"cell_type":"markdown","metadata":{"id":"p3WhQof2lfOP"},"source":["# 8 Load metrices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WBtjDHvUltjc"},"outputs":[],"source":["folder_in_output = '/10.10.2022 12:51:24/'\n","\n","train_loss_arr = load_list(config['output_path']+folder_in_output+'train_loss_arr.pkl')\n","train_mPrecision_arr = load_list(config['output_path']+folder_in_output+'train_mPrecision_arr.pkl')\n","train_mRecall_arr = load_list(config['output_path']+folder_in_output+'train_mRecall_arr.pkl')\n","train_mIOU_arr = load_list(config['output_path']+folder_in_output+'train_mIOU_arr.pkl')\n","train_DSC_arr = load_list(config['output_path']+folder_in_output+'train_DSC_arr.pkl')\n","valid_loss_epoch_arr = load_list(config['output_path']+folder_in_output+'valid_loss_epoch_arr.pkl')\n","valid_mPrecision_arr = load_list(config['output_path']+folder_in_output+'valid_mPrecision_arr.pkl')\n","valid_mRecall_arr = load_list(config['output_path']+folder_in_output+'valid_mRecall_arr.pkl')\n","valid_mIOU_arr = load_list(config['output_path']+folder_in_output+'valid_mIOU_arr.pkl')\n","valid_DSC_arr = load_list(config['output_path']+folder_in_output+'valid_DSC_arr.pkl')\n"]},{"cell_type":"markdown","metadata":{"id":"FdJFxbsnmsez"},"source":["# 9 Plot metrices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V5BFDHJDmySF"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from matplotlib.ticker import MaxNLocator\n","\n","fig, axs = plt.subplots(1, 5,)\n","fig.set_size_inches((26, 4))\n","\n","#loss\n","i = 0\n","axs[i].plot (train_loss_arr , label = \"Train\" , marker='o')\n","axs[i].plot (valid_loss_epoch_arr , label = \"Test\" , marker='o')\n","axs[i].set_ylabel ('loss')\n","axs[i].set_title ('DoubleAU-Net loss')\n","axs[i].set_xlabel ('Epoch')\n","\n","#mPrecision\n","i+=1\n","axs[i].plot (train_mPrecision_arr , label = \"Train\" , marker='o')\n","axs[i].plot (valid_mPrecision_arr , label = \"Test\" , marker='o')\n","axs[i].set_ylabel ('mPrecision')\n","axs[i].set_title ('DoubleAU-Net mPrecision')\n","\n","#mRecall\n","i+=1\n","axs[i].plot (train_mRecall_arr , label = \"Train\" , marker='o')\n","axs[i].plot (valid_mRecall_arr , label = \"Test\" , marker='o')\n","axs[i].set_title ('DoubleAU-Net mRecall')\n","axs[i].set_ylabel ('mRecall')\n","\n","#mIOU\n","i+=1\n","axs[i].plot (train_mIOU_arr , label = \"Train\" , marker='o')\n","axs[i].plot (valid_mIOU_arr , label = \"Test\" , marker='o')\n","axs[i].set_title ('DoubleAU-Net mIOU')\n","axs[i].set_ylabel ('mIOU')\n","\n","#mDSC\n","i+=1\n","axs[i].plot (train_DSC_arr , label = \"Train\" , marker='o')\n","axs[i].plot (valid_DSC_arr , label = \"Test\" , marker='o')\n","axs[i].set_title ('DoubleAU-Net DSC')\n","axs[i].set_ylabel ('DSC')\n","\n","for j in range(5):\n","  axs[j].set_xlabel ('Epoch')\n","  axs[j].xaxis.set_major_locator(MaxNLocator(integer=True))\n","  axs[j].legend()\n","  axs[j].grid()"]},{"cell_type":"markdown","metadata":{"id":"R62tAUMc258T"},"source":["# 10 Final model test"]},{"cell_type":"markdown","metadata":{"id":"E3W5EbGLsACh"},"source":["## 10.1 Load model function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gGKF2tF2otei"},"outputs":[],"source":["def load_model(model_path):\n","    #folder_in_output = '/09.09.2022 16:58:04/'\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    DoubleUNet_model = DoubleUNet().to(device)\n","    loaded_model = DoubleUNet_model\n","    loaded_model.eval()\n","    loaded_model.load_state_dict(torch.load(model_path,map_location=torch.device(device)))\n","    loaded_model.eval()\n","    return loaded_model\n","\n","  "]},{"cell_type":"markdown","metadata":{"id":"__MUG8ydjycp"},"source":["## 10.2 Test function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tVTzob_5irI3"},"outputs":[],"source":["def final_test(model,valid_data,output_file_path):\n","    model.eval()\n","    valid_loss = 0\n","    mPrecision=0\n","    mRecall=0\n","    mIOU=0\n","    avg_batch_valid_DSC=0\n","    \n","    num_batches = len(valid_data)\n","    with torch.no_grad():\n","        for batch_idx,batch in enumerate(valid_data):\n","            # Getting the batch data:\n","            x = batch['image'].to(device) #GPU\n","            y = batch['mask'].to(device) # GPU\n","\n","            # Getting predictions:\n","            y_pred = model(x)\n","            \n","            if config['dataset']=='CVC':\n","              batch_loss = bce_dice_loss(y,y_pred)\n","            elif config['dataset']=='bowl':\n","              batch_loss = dice_loss(y,y_pred)\n","              \n","            batch_valid_DSC = dice_coef(y,y_pred)\n","\n","            #print(batch_loss)\n","            avg_batch_valid_DSC += batch_valid_DSC.sum()/(len(batch_valid_DSC))\n","            loss = batch_loss.sum()/(len(batch_loss))\n","            valid_loss+=loss #sums up all avg batch losses\n","\n","            # Calculating Accuracy:\n","            precision, recall = calculate_prec_rec(y, y_pred)\n","            pred_iou = iou(y, y_pred)\n","\n","            mPrecision+=precision.sum()/(len(precision)) #mean precision of a batch and sums them up\n","            mRecall+=recall.sum()/(len(recall)) #mean recall of a batch and sums them up\n","            mIOU+=pred_iou.sum()/(len(pred_iou)) #mean IOU of a batch and sums them up\n","\n","    valid_loss /= num_batches\n","    valid_DSC = avg_batch_valid_DSC / num_batches\n","    print_both('\\n~~~~~~~~~~~~~~~~~ Test Loss: {:.4f} ~~~~~~~~~~~~~~~~~\\n'.format(valid_loss),output_file_path = output_file_path)\n","    print_both('mean Precision:{}   |    mean Recall:{}   |    mIOU:{}    |   DSC:{}\\n'.format(mPrecision/ num_batches, mRecall/ num_batches, mIOU/ num_batches, valid_DSC),output_file_path = output_file_path)\n","    \n","    return valid_loss.item(), valid_DSC.item(), (mPrecision/ num_batches).item(), (mRecall/ num_batches).item(), (mIOU/ num_batches).item()"]},{"cell_type":"markdown","metadata":{"id":"HfeAdgbhj1x5"},"source":["## 10.3 Test loaded model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-SfVOONYjuD5"},"outputs":[],"source":["folder_in_output = '/10.10.2022 12:51:24/'\n","model_name = 'DoubleUNet.pth'\n","model_path = config['output_path']+folder_in_output+model_name\n","test_output_path = config['output_path']+folder_in_output+'final_test'+model_name+'.txt'\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","loaded_model = load_model(model_path)\n","loaded_model.eval()\n","#print(loaded_model)\n","#test_loss, test_DSC, test_mPrecision, test_mRecall, test_mIOU = final_test(loaded_model, test_dataloader, test_output_path)\n","\n"]},{"cell_type":"code","source":["batch = next(iter(test_dataloader))\n","x = batch['image'].to(device) #GPU\n","y = batch['mask'].to(device) # GPU\n","y_pred = loaded_model(x)\n","y_pred = torch.round(y_pred)\n","\n","\n","x = x.permute(0,2,3,1)\n","test_images= [cv2.cvtColor(x[i,:,:,:].cpu().detach().numpy(), cv2.COLOR_BGR2RGB) for i in range(0,config['batch_size'])]\n","\n","figure = plt.figure(figsize=[15, 15])\n","figure.subplots_adjust(wspace=0.1, hspace=0.1)\n","\n","for i in range(4):\n","  figure.add_subplot(4,3,3*i+1).set_aspect('equal')\n","  plt.title('Input')\n","  plt.axis('off')\n","  plt.imshow(test_images[i+6])\n","  figure.add_subplot(4,3,3*i+2).set_aspect('equal')\n","  plt.title('Ground Truth')\n","  plt.axis('off')\n","  plt.imshow(torchvision.utils.make_grid(y[i+6].cpu(), nrow=1).permute(1, 2, 0))\n","  figure.add_subplot(4,3,3*i+3).set_aspect('equal')\n","  plt.title('Output2')\n","  plt.axis('off')\n","  plt.imshow(torchvision.utils.make_grid(y_pred[i+6].cpu(), nrow=1).permute(1, 2, 0))\n","\n","figure.subplots_adjust(wspace=0.1, hspace=0.1)\n"],"metadata":{"id":"7CuAzruhB8J6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["num of parameters:"],"metadata":{"id":"7KgSp_6cK4Av"}},{"cell_type":"code","source":["from prettytable import PrettyTable\n","\n","def count_parameters(model):\n","    table = PrettyTable([\"Modules\", \"Parameters\"])\n","    total_params = 0\n","    for name, parameter in model.named_parameters():\n","        if not parameter.requires_grad: continue\n","        params = parameter.numel()\n","        table.add_row([name, params])\n","        total_params+=params\n","    print(table)\n","    print(f\"Total Trainable Params: {total_params}\")\n","    return total_params\n","    \n","count_parameters(loaded_model)"],"metadata":{"id":"jWUB9HhSd0vI"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}